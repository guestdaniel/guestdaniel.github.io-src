Title: Research 
Date: 2017-04-01 10:00

[UMN Auditory Perception and Cognition Lab][7]
-----------------

**Time**: September 2017 - present

**PI:** Andrew Oxenham

I joined the Auditory Perception and Cognition Lab in September 2017. My research spans a variety of topics in psychacoustics:

- **Neural basis of pitch perception:** One of my current projects focuses on examining pitch perception with harmonic complex tones composed entirely of high frequencies (i.e., > 8 kHz). Previous research has demonstrated accurate pitch perception with such stimuli, and my present goal is to further investigate the neural code which mediates this pitch percept. To this end, I am investigating the ability of listeners to percieve pitch of high-frequency complex tone in the context of concurrent and spectrally-overlapping complex tone maskers. Additionally, I am developing computational models of neural responses to the stimuli used in these experiments in an effort to account for the results quantitatively.
:   [Poster presented at ARO 2019]({filename}/download/GuestOxenhamARO19.pdf)

- **Auditory enhancement:** I am currently assisting on a project pertaining to the neural correlates of auditory enhancement (measured by EEG). My role focuses on building a computational model of auditory enhancement to account for the electrophysiological measurements.

- **Role of pitch in the complex auditory scene:** In my first project in the lab, I examined how F0 differences between a target talker and harmonic complex tone masker benefit speech segregation under a variety of conditions.
:   [Poster presented at ASA Fall 2018]({filename}/download/GuestOxenhamASAVictoria18.pdf)   
    [Poster presented at UMN CCS Spring Research Day 2018]({filename}/download/GuestOxenhamSRD18.pdf)

[UMN Computational Visual Neuroscience Lab](http://cvnlab.net/home.shtml)
-----------------

**Time**: March 2019 - present

**PI:** Kendrick Kay 

As part of my [NSF-NRT Graduate Training Program in Sensory Science Fellowship](http://catss.umn.edu/opportunities.htm), I am currently participating in a rotation in the UMN Computational Visual Neuroscience Lab. For my rotation, I am working on implementation and analysis of visual encoding models for a multi-session, multi-subject, high-resolution fMRI dataset currently being collected at the [Center for Magnetic Resonance Research](https://www.cmrr.umn.edu/). 

[UT Dallas Speech Perception Lab][1]
-----------------

**Time**: May 2015 - May 2017 

**PI:** Peter Assmann

As an undergraduate research assistant, my primary role was working on a project investigating perception of indexical properties in children's speech. Using stimuli from the North Texas Vowel Database modified by the [STRAIGHT vocoder][3], I examined how listeners utilize fundamental frequency and formant frequencies when perceiving age and gender in children's speech. In particular, I focused on conditions of reduced spectrotemporal resolution (through the use of tone vocoders) and on differences between normal-hearing and cochlear-implant listeners. This research culminated in an honors thesis entitled "Perception of voice gender in children's speech". 
:  [Poster presented at ASA Spring 2017][9]   
   [Poster presented at UTD Undergraduate Poster Contest 2017][8]   
   [Poster presented at ASA Spring 2016][2]


[1]: https://www.utdallas.edu/~assmann/ 
[2]: {filename}/download/GuestetalASA16.pdf
[3]: www.wakayama-u.ac.jp/~kawahara/STRAIGHTadv/index_e.html 
[7]: http://apc.psych.umn.edu
[8]: {filename}/download/GuestAEEUR17.pdf
[9]: {filename}/download/GuestetalASA17.pdf
